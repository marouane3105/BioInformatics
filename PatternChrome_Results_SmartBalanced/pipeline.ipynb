{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6d05ea",
   "metadata": {},
   "source": [
    "## Paper Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b7f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from pyswarm import pso\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_SIZE = 50 # number of bins for binned sequencing data\n",
    "NUM_CPS = 2 # number of control points per pattern\n",
    "MP_CUTOFF = 0.3 # min pattern match threshold to count it\n",
    "\n",
    "ETA = 0.2 # learning rate for XGBoost\n",
    "NROUNDS = 5 # number of boosting rounds\n",
    "\n",
    "PSO_SWARMSIZE = 5 # number of particles in the PSO swarm\n",
    "PSO_MAXITER = 4 # max number of PSO iterations\n",
    "\n",
    "SEQ_BASE = \"Converted_binned_sequencing_data\"\n",
    "LABEL_BASE = \"GE_Labels\"\n",
    "SPLIT_BASE = \"Gene_Splits\"\n",
    "OUTPUT_BASE = \"PatternChrome_Results_SmartBalanced\"\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9bb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads histone modification data for a cell line\n",
    "def load_histone_data(cell):\n",
    "    mods = [\"H3K4me1\", \"H3K4me3\", \"H3K9me3\", \"H3K27me3\", \"H3K36me3\"]\n",
    "    return {\n",
    "        mod: pd.read_csv(os.path.join(SEQ_BASE, cell, f\"{mod}_{BIN_SIZE}bp_bins.csv\"), index_col=0)\n",
    "        for mod in mods\n",
    "    }\n",
    "\n",
    "# loads GE labels and train/val/test gene splits for a cell line\n",
    "def load_labels_and_splits(cell):\n",
    "    y_train = pd.read_csv(os.path.join(LABEL_BASE, cell, \"train_labels.csv\"), index_col=\"gene_id\").squeeze()\n",
    "    y_val   = pd.read_csv(os.path.join(LABEL_BASE, cell, \"validation_labels.csv\"), index_col=\"gene_id\").squeeze()\n",
    "    y_test  = pd.read_csv(os.path.join(LABEL_BASE, cell, \"test_labels.csv\"), index_col=\"gene_id\").squeeze()\n",
    "    g_train = pd.read_csv(os.path.join(SPLIT_BASE, cell, \"train_genes.csv\"), header=None).squeeze().tolist()\n",
    "    g_val   = pd.read_csv(os.path.join(SPLIT_BASE, cell, \"validation_genes.csv\"), header=None).squeeze().tolist()\n",
    "    g_test  = pd.read_csv(os.path.join(SPLIT_BASE, cell, \"test_genes.csv\"), header=None).squeeze().tolist()\n",
    "    return (y_train, y_val, y_test), (g_train, g_val, g_test)\n",
    "\n",
    "# counts how many times a pattern occurs in each row with corr > threshold\n",
    "def pattern_frequency(df, pattern, threshold, n_jobs=-1):\n",
    "    width = len(pattern)\n",
    "    \n",
    "    def count_matches(values):\n",
    "        count = 0\n",
    "        for i in range(len(values) - width + 1):\n",
    "            segment = values[i:i + width]\n",
    "            if np.std(segment) == 0 or np.std(pattern) == 0:\n",
    "                continue\n",
    "            corr = np.corrcoef(segment, pattern)[0, 1]\n",
    "            if not np.isnan(corr) and corr > threshold:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "    rows = df.to_numpy()\n",
    "    return np.array(Parallel(n_jobs=n_jobs)(delayed(count_matches)(row) for row in rows))\n",
    "\n",
    "# returns negative AUC for given pattern and region â€“ used by PSO\n",
    "def objective_function(params, hm_train, y, threshold):\n",
    "    start, end = int(params[0]), int(params[1])\n",
    "    if end <= start or (end - start) < NUM_CPS:\n",
    "        return 0  # invalid region\n",
    "    pattern = params[2:]\n",
    "    region = hm_train.iloc[:, start:end]\n",
    "    freq = pattern_frequency(region, pattern, threshold, n_jobs=-1)\n",
    "    if np.all(freq == 0): return 0\n",
    "    model = XGBClassifier(n_estimators=NROUNDS, eta=ETA, use_label_encoder=False, eval_metric=\"auc\", verbosity=0)\n",
    "    model.fit(freq.reshape(-1, 1), y)\n",
    "    return -roc_auc_score(y, model.predict_proba(freq.reshape(-1, 1))[:, 1])  # we minimize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb72aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runs full pipeline for a given cell line: pattern extraction, feature selection, hyperparameter tuning, evaluation\n",
    "def process_cell(cell):\n",
    "    cell_out = os.path.join(OUTPUT_BASE, cell)\n",
    "    os.makedirs(cell_out, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        histones = load_histone_data(cell)\n",
    "        (y_train, y_val, y_test), (g_train, g_val, g_test) = load_labels_and_splits(cell)\n",
    "    except:\n",
    "        return None  # skip if data loading fails\n",
    "\n",
    "    common_train = list(set(g_train) & set(y_train.index))\n",
    "    common_val = list(set(g_val) & set(y_val.index))\n",
    "    common_test = list(set(g_test) & set(y_test.index))\n",
    "    train_df = pd.DataFrame({\"GE\": y_train.loc[common_train]})\n",
    "    val_df = pd.DataFrame({\"GE\": y_val.loc[common_val]})\n",
    "    test_df = pd.DataFrame({\"GE\": y_test.loc[common_test]})\n",
    "\n",
    "    patterns_info = []\n",
    "\n",
    "    # === 2. Pattern extraction using PSO ===\n",
    "    for idx in range(NUM_CPS):\n",
    "        best_auc = -np.inf\n",
    "        best_entry = None\n",
    "\n",
    "        for mod_name, hm_data in histones.items():\n",
    "            try:\n",
    "                hm_train = hm_data.loc[common_train]\n",
    "                lb = [0, NUM_CPS] + [0] * NUM_CPS\n",
    "                ub = [hm_train.shape[1], hm_train.shape[1]] + [1] * NUM_CPS\n",
    "                args = (hm_train, y_train.loc[common_train], MP_CUTOFF)\n",
    "\n",
    "                best_params, _ = pso(objective_function, lb, ub, args=args,\n",
    "                                     swarmsize=PSO_SWARMSIZE, maxiter=PSO_MAXITER, debug=False)\n",
    "                pattern = best_params[2:]\n",
    "                start, end = int(best_params[0]), int(best_params[1])\n",
    "                region = hm_train.iloc[:, start:end]\n",
    "                freq = pattern_frequency(region, pattern, MP_CUTOFF, n_jobs=-1)\n",
    "\n",
    "                if np.all(freq == 0):\n",
    "                    continue\n",
    "\n",
    "                model = XGBClassifier(n_estimators=NROUNDS, eta=ETA, eval_metric=\"auc\", use_label_encoder=False, verbosity=0)\n",
    "                model.fit(freq.reshape(-1, 1), y_train.loc[common_train])\n",
    "                auc = roc_auc_score(y_train.loc[common_train], model.predict_proba(freq.reshape(-1, 1))[:, 1])\n",
    "\n",
    "                if auc > best_auc:\n",
    "                    best_entry = {\"pattern\": pattern, \"start\": start, \"end\": end, \"freq\": freq, \"mod\": mod_name}\n",
    "                    best_auc = auc\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # add best pattern as new feature if found\n",
    "        if best_entry:\n",
    "            pat_name = f\"Pattern_{len(train_df.columns)}\"\n",
    "            train_df[pat_name] = best_entry[\"freq\"]\n",
    "            val_df[pat_name] = pattern_frequency(\n",
    "                histones[best_entry[\"mod\"]].loc[common_val].iloc[:, best_entry[\"start\"]:best_entry[\"end\"]],\n",
    "                best_entry[\"pattern\"], MP_CUTOFF, n_jobs=-1\n",
    "            )\n",
    "            test_df[pat_name] = pattern_frequency(\n",
    "                histones[best_entry[\"mod\"]].loc[common_test].iloc[:, best_entry[\"start\"]:best_entry[\"end\"]],\n",
    "                best_entry[\"pattern\"], MP_CUTOFF, n_jobs=-1\n",
    "            )\n",
    "            patterns_info.append({\n",
    "                \"Pattern\": pat_name, \"HM\": best_entry[\"mod\"],\n",
    "                \"Start\": best_entry[\"start\"], \"End\": best_entry[\"end\"], \"Width\": len(best_entry[\"pattern\"]),\n",
    "                **{f\"Point_{i}\": p for i, p in enumerate(best_entry[\"pattern\"])}\n",
    "            })\n",
    "\n",
    "    # skip if no features were extracted\n",
    "    features = list(train_df.columns[1:])\n",
    "    if not features:\n",
    "        return None\n",
    "\n",
    "    # === 3. Feature selection via backward elimination ===\n",
    "    model = XGBClassifier(n_estimators=NROUNDS, eta=ETA, eval_metric=\"auc\", use_label_encoder=False)\n",
    "    model.fit(train_df[features], train_df[\"GE\"])\n",
    "    best_auc = roc_auc_score(val_df[\"GE\"], model.predict_proba(val_df[features])[:, 1])\n",
    "\n",
    "    for feature in reversed(features):\n",
    "        reduced = features.copy()\n",
    "        reduced.remove(feature)\n",
    "        if not reduced:\n",
    "            continue\n",
    "        model.fit(train_df[reduced], train_df[\"GE\"])\n",
    "        auc = roc_auc_score(val_df[\"GE\"], model.predict_proba(val_df[reduced])[:, 1])\n",
    "        if auc >= best_auc:\n",
    "            features = reduced\n",
    "            best_auc = auc\n",
    "\n",
    "    # save filtered feature matrix\n",
    "    train_df[[\"GE\"] + features].to_csv(os.path.join(cell_out, \"features_selected.csv\"))\n",
    "\n",
    "    # === 4. Hyperparameter tuning using PSO ===\n",
    "    def hp_objective(params, X, y, X_val, y_val):\n",
    "        try:\n",
    "            m = XGBClassifier(\n",
    "                n_estimators=int(params[0]), eta=params[1], gamma=params[2],\n",
    "                max_depth=int(params[3]), reg_lambda=params[4], reg_alpha=params[5],\n",
    "                min_child_weight=params[6], subsample=params[7],\n",
    "                use_label_encoder=False, eval_metric=\"auc\", verbosity=0\n",
    "            )\n",
    "            m.fit(X, y, eval_set=[(X_val, y_val)], early_stopping_rounds=15, verbose=False)\n",
    "            return -roc_auc_score(y_val, m.predict_proba(X_val)[:, 1])\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    hp_lb = [100, 0.001, 0.0, 2, 0.0, 0.0, 0.0, 0.1]\n",
    "    hp_ub = [1500, 0.5, 20.0, 20, 10.0, 10.0, 50.0, 1.0]\n",
    "\n",
    "    best_hp, best_val_score = pso(hp_objective, hp_lb, hp_ub,\n",
    "                                   args=(train_df[features], train_df[\"GE\"], val_df[features], val_df[\"GE\"]),\n",
    "                                   swarmsize=PSO_SWARMSIZE, maxiter=PSO_MAXITER)\n",
    "\n",
    "    # === 5. Final training and evaluation on test set ===\n",
    "    final_model = XGBClassifier(\n",
    "        n_estimators=int(best_hp[0]), eta=best_hp[1], gamma=best_hp[2],\n",
    "        max_depth=int(best_hp[3]), reg_lambda=best_hp[4], reg_alpha=best_hp[5],\n",
    "        min_child_weight=best_hp[6], subsample=best_hp[7],\n",
    "        use_label_encoder=False, eval_metric=\"auc\", verbosity=0,\n",
    "        early_stopping_rounds=15\n",
    "    )\n",
    "\n",
    "    final_model.fit(\n",
    "        train_df[features], train_df[\"GE\"],\n",
    "        eval_set=[(val_df[features], val_df[\"GE\"])]\n",
    "    )\n",
    "\n",
    "    test_auc = roc_auc_score(test_df[\"GE\"], final_model.predict_proba(test_df[features])[:, 1])\n",
    "\n",
    "    # === 6. Save final results ===\n",
    "    result = {\n",
    "        \"Cell\": cell,\n",
    "        \"Test_AUC\": round(test_auc, 5),\n",
    "        \"Validation_AUC\": round(abs(best_val_score), 5),\n",
    "        **{k: round(v, 5) for k, v in zip(\n",
    "            [\"n_estimators\", \"eta\", \"gamma\", \"max_depth\", \"lambda\", \"alpha\", \"min_child_weight\", \"subsample\"],\n",
    "            best_hp\n",
    "        )}\n",
    "    }\n",
    "\n",
    "    pd.DataFrame([result]).to_csv(os.path.join(cell_out, \"final_results_with_hyperparams_tuned.csv\"), index=False)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9eb89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# get all available cell line folders\n",
    "all_cells = [d for d in os.listdir(SEQ_BASE) if os.path.isdir(os.path.join(SEQ_BASE, d))]\n",
    "all_cells.sort()\n",
    "\n",
    "# run full pipeline for each cell line\n",
    "for cell in all_cells:\n",
    "    result = process_cell(cell)\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "summary_path = os.path.join(OUTPUT_BASE, \"test_results.csv\")\n",
    "pd.DataFrame(results).to_csv(summary_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163efe0e",
   "metadata": {},
   "source": [
    "## Report Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea33ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette = {\n",
    "    \"PatternChrome (paper)\": \"#1f77b4\",\n",
    "    \"PatternChrome (ours)\": \"#ff7f0e\",\n",
    "    \"PatternChrome (tuned)\": \"#9467bd\",\n",
    "    \"ShallowChrome\": \"#2ca02c\",\n",
    "    \"DeepChrome\": \"#d62728\"\n",
    "}\n",
    "\n",
    "performance_df = pd.read_csv(\"PatternChrome_Results/performance_Metrics.csv\")\n",
    "test_results_df = pd.read_csv(\"PatternChrome_Results/test_results.csv\")\n",
    "test_results_tuned_df = pd.read_csv(\"PatternChrome_Results_SmartBalanced/test_results.csv\")\n",
    "\n",
    "cell_lines = performance_df[\"cell_line\"].tolist()\n",
    "\n",
    "pattern_paper_auc = performance_df[\"AUC\"].tolist()\n",
    "pattern_ours_auc = test_results_df.set_index(\"Cell\").loc[cell_lines][\"Test_AUC\"].tolist()\n",
    "pattern_tuned_auc = test_results_tuned_df.set_index(\"Cell\").loc[cell_lines][\"Test_AUC\"].tolist()\n",
    "\n",
    "deepchrome = [0.77,0.81,0.8,0.82,0.77,0.76,0.8,0.79,0.79,0.77,0.8,0.81,0.81,0.83,0.83,0.8,0.8,0.8,0.83,0.89,0.9,0.84,0.9,0.84,0.8,0.76,0.8,0.76,0.73,0.74,0.78,0.71,0.72,0.74,\n",
    "              0.73,0.82,0.72,0.76,0.74,0.9,0.79,0.78,0.76,0.74,0.69,0.73,0.83,0.91,0.92,0.85,0.83,0.84,0.83,0.92,0.83,0.83]\n",
    "shallowchrome = [0.878,0.879,0.884,0.872,0.887,0.874,0.898,0.891,0.885,0.880,0.868,0.887,0.891,0.891,0.898,0.905,\n",
    "                 0.893,0.888,0.901,0.891,0.882,0.893,0.876,0.891,0.883,0.804,0.850,0.85756,0.81386,0.84087,0.86323,\n",
    "                 0.85549,0.86363,0.83924,0.82661,0.87473,0.84089,0.84009,0.8425,0.88465,0.84114,0.85575,0.84818,\n",
    "                 0.83271,0.83361,0.85408,0.89235,0.90511,0.913,0.90319,0.89433,0.89197,0.88881,0.91957,0.89446,0.89072]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"cell_line\": cell_lines * 5,\n",
    "    \"AUC\": pattern_paper_auc + pattern_ours_auc + pattern_tuned_auc + shallowchrome + deepchrome,\n",
    "    \"Model\": [\"PatternChrome (paper)\"] * 56 +\n",
    "             [\"PatternChrome (ours)\"] * 56 +\n",
    "             [\"PatternChrome (tuned)\"] * 56 +\n",
    "             [\"ShallowChrome\"] * 56 +\n",
    "             [\"DeepChrome\"] * 56\n",
    "})\n",
    "\n",
    "# Violin plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(data=df, x=\"Model\", y=\"AUC\", palette=custom_palette, inner=\"box\")\n",
    "sns.stripplot(data=df, x=\"Model\", y=\"AUC\", color=\"black\", size=2, alpha=0.5, jitter=True)\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.title(\"AUC Distribution per Model\")\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x=\"Model\", y=\"AUC\", palette=custom_palette)\n",
    "sns.pointplot(data=df, x=\"Model\", y=\"AUC\", estimator=np.mean, color='black', markers='D', join=False, ci=None)\n",
    "plt.title(\"Boxplot with Mean Marker per Model\")\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mean and standard deviation\n",
    "summary = df.groupby(\"Model\")[\"AUC\"].agg([\"mean\", \"std\"]).reset_index()\n",
    "summary.plot(\n",
    "    kind='bar',\n",
    "    x='Model',\n",
    "    y='mean',\n",
    "    yerr='std',\n",
    "    legend=False,\n",
    "    figsize=(10, 6),\n",
    "    color=[custom_palette[m] for m in summary[\"Model\"]]\n",
    ")\n",
    "plt.title(\"Mean AUC with Standard Deviation\")\n",
    "plt.ylabel(\"Mean AUC\")\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Lineplot\n",
    "pivot_df = df.pivot(index='cell_line', columns='Model', values='AUC').reset_index()\n",
    "melted_line = pd.melt(pivot_df, id_vars='cell_line', var_name='Model', value_name='AUC')\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(data=melted_line, x=\"cell_line\", y=\"AUC\", hue=\"Model\", style=\"Model\", markers=True, dashes=False, palette=custom_palette)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"AUC per Cell Line for Each Model\")\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Barplot with min, max and mean AUC per model\n",
    "summary_minmaxavg = df.groupby(\"Model\")[\"AUC\"].agg([\"mean\", \"min\", \"max\"]).reset_index()\n",
    "summary_melted = pd.melt(summary_minmaxavg, id_vars=\"Model\", var_name=\"Metric\", value_name=\"AUC\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=summary_melted, x=\"Model\", y=\"AUC\", hue=\"Metric\", palette=\"Set2\")\n",
    "plt.title(\"Min, Max, and Mean AUC per Model\")\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.ylim(0.6, 1.0)\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
